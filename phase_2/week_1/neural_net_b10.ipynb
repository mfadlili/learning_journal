{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_net_b10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network with Tensorflow\n",
        "\n",
        "Langkah membuat neural network : \n",
        "\n",
        "- Siapkan Data -> Fitur\n",
        "  - Open / Gather data\n",
        "  - Preprocessing\n",
        "  - Feature Engineering\n",
        "- Buat Arsitektur NN\n",
        "  - Sequential API\n",
        "  - Functional API\n",
        "- Compile (translate kode -> bahasa mesin) Model NN\n",
        "  - Tentukan Loss yang digunakan\n",
        "  - Tentukan Optimizer yang digunakan\n",
        "  - Tentukan metrik yang ingin dimonitor\n",
        "  - Callback\n",
        "- Training"
      ],
      "metadata": {
        "id": "h7Qu2vKSzEMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling with Titanic Data"
      ],
      "metadata": {
        "id": "rgNkH1Mb1qSl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "AHKq6QCoxHr3",
        "outputId": "8625a68b-3a1b-4c9a-ee8c-02115b7e004b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Survived  Pclass  \\\n",
              "PassengerId                     \n",
              "1                   0       3   \n",
              "2                   1       1   \n",
              "3                   1       3   \n",
              "4                   1       1   \n",
              "5                   0       3   \n",
              "\n",
              "                                                          Name     Sex   Age  \\\n",
              "PassengerId                                                                    \n",
              "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
              "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
              "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
              "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
              "5                                     Allen, Mr. William Henry    male  35.0   \n",
              "\n",
              "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
              "PassengerId                                                          \n",
              "1                1      0         A/5 21171   7.2500   NaN        S  \n",
              "2                1      0          PC 17599  71.2833   C85        C  \n",
              "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "4                1      0            113803  53.1000  C123        S  \n",
              "5                0      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47638806-ed71-412b-ad03-ed5a6c53f1e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47638806-ed71-412b-ad03-ed5a6c53f1e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47638806-ed71-412b-ad03-ed5a6c53f1e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47638806-ed71-412b-ad03-ed5a6c53f1e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/afifai/pelatihan_machinelearning/master/data/train.csv\", index_col=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "d0QetzqU1vIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=46)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=46)"
      ],
      "metadata": {
        "id": "kbf2gKSR11Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_col = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "cat_col = ['Sex']\n",
        "\n",
        "num_pipeline = make_pipeline(SimpleImputer(strategy='median'),\n",
        "                             StandardScaler())\n",
        "\n",
        "cat_pipeline = make_pipeline(OneHotEncoder())\n",
        "\n",
        "data_pipeline = ColumnTransformer([\n",
        "    ('pipe_num', num_pipeline, num_col),\n",
        "    ('pipe_cat', cat_pipeline, cat_col)\n",
        "])"
      ],
      "metadata": {
        "id": "52ushkJp2aWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ekstrak fitur\n",
        "X_train = data_pipeline.fit_transform(X_train)\n",
        "X_val = data_pipeline.transform(X_val)\n",
        "X_test = data_pipeline.transform(X_test)"
      ],
      "metadata": {
        "id": "0eHodW1t3DKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wa2hSNm5M9w",
        "outputId": "0ef4e7b5-780b-4f00-ea6b-c8333c55fc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(681, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtmRr_kq5RQA",
        "outputId": "2cc7671d-c4c2-47b0-dbdb-cb2da00f41ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdcjYDbC5YBJ",
        "outputId": "d77a5fc8-1ce6-4150-fe34-70d7087b2121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Buat Arsitektur NN"
      ],
      "metadata": {
        "id": "0g7KMn1T5hbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sequential API\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\"\"\"\n",
        "functional api\n",
        "\n",
        "data_in = Input(shape=(7,))\n",
        "hidden_1 = Dense(4, activation='relu')(data_in)\n",
        "out = Dense(1, activation='sigmoid')(hidden_1)\n",
        "\n",
        "model = Model(inputs=data_in, outputs=out)\n",
        "\"\"\"\n",
        "\n",
        "# buat arsitekturnya\n",
        "model = Sequential()\n",
        "model.add(Dense(4, activation='relu', input_shape=(7,))) # hidden layer 1\n",
        "model.add(Dense(1, activation='sigmoid')) # output layer\n",
        "\n",
        "\n",
        "# compile\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', # paling modern\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train\n",
        "history = model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWeJM4i35kAD",
        "outputId": "08b32a81-e421-4520-9752-051eaeca48f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "22/22 [==============================] - 1s 12ms/step - loss: 0.6509 - accuracy: 0.6535 - val_loss: 0.6393 - val_accuracy: 0.6974\n",
            "Epoch 2/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6299 - accuracy: 0.6916 - val_loss: 0.6202 - val_accuracy: 0.6447\n",
            "Epoch 3/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.6769 - val_loss: 0.6045 - val_accuracy: 0.6447\n",
            "Epoch 4/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.6755 - val_loss: 0.5917 - val_accuracy: 0.6447\n",
            "Epoch 5/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.6769 - val_loss: 0.5815 - val_accuracy: 0.6447\n",
            "Epoch 6/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5741 - accuracy: 0.6740 - val_loss: 0.5734 - val_accuracy: 0.6447\n",
            "Epoch 7/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.6755 - val_loss: 0.5670 - val_accuracy: 0.6316\n",
            "Epoch 8/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.6769 - val_loss: 0.5621 - val_accuracy: 0.6316\n",
            "Epoch 9/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.6799 - val_loss: 0.5577 - val_accuracy: 0.6316\n",
            "Epoch 10/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.6799 - val_loss: 0.5542 - val_accuracy: 0.6447\n",
            "Epoch 11/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5423 - accuracy: 0.6872 - val_loss: 0.5510 - val_accuracy: 0.6447\n",
            "Epoch 12/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.6946 - val_loss: 0.5483 - val_accuracy: 0.6447\n",
            "Epoch 13/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7019 - val_loss: 0.5454 - val_accuracy: 0.6579\n",
            "Epoch 14/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7034 - val_loss: 0.5429 - val_accuracy: 0.6579\n",
            "Epoch 15/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7137 - val_loss: 0.5398 - val_accuracy: 0.6447\n",
            "Epoch 16/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7327 - val_loss: 0.5373 - val_accuracy: 0.6842\n",
            "Epoch 17/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7489 - val_loss: 0.5341 - val_accuracy: 0.6974\n",
            "Epoch 18/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.7474 - val_loss: 0.5312 - val_accuracy: 0.6974\n",
            "Epoch 19/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.7577 - val_loss: 0.5288 - val_accuracy: 0.6974\n",
            "Epoch 20/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7606 - val_loss: 0.5264 - val_accuracy: 0.7105\n",
            "Epoch 21/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7621 - val_loss: 0.5241 - val_accuracy: 0.7105\n",
            "Epoch 22/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7709 - val_loss: 0.5213 - val_accuracy: 0.7105\n",
            "Epoch 23/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7709 - val_loss: 0.5185 - val_accuracy: 0.7237\n",
            "Epoch 24/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.7768 - val_loss: 0.5165 - val_accuracy: 0.7105\n",
            "Epoch 25/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7930 - val_loss: 0.5127 - val_accuracy: 0.7237\n",
            "Epoch 26/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7930 - val_loss: 0.5098 - val_accuracy: 0.7237\n",
            "Epoch 27/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.7915 - val_loss: 0.5075 - val_accuracy: 0.7237\n",
            "Epoch 28/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7944 - val_loss: 0.5042 - val_accuracy: 0.7237\n",
            "Epoch 29/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7900 - val_loss: 0.5011 - val_accuracy: 0.7368\n",
            "Epoch 30/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7974 - val_loss: 0.4988 - val_accuracy: 0.7237\n",
            "Epoch 31/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7974 - val_loss: 0.4970 - val_accuracy: 0.7368\n",
            "Epoch 32/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7974 - val_loss: 0.4946 - val_accuracy: 0.7368\n",
            "Epoch 33/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7974 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
            "Epoch 34/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7988 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
            "Epoch 35/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.8018 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
            "Epoch 36/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7988 - val_loss: 0.4836 - val_accuracy: 0.7500\n",
            "Epoch 37/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7974 - val_loss: 0.4829 - val_accuracy: 0.7500\n",
            "Epoch 38/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.8003 - val_loss: 0.4807 - val_accuracy: 0.7500\n",
            "Epoch 39/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.8003 - val_loss: 0.4796 - val_accuracy: 0.7500\n",
            "Epoch 40/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.8003 - val_loss: 0.4784 - val_accuracy: 0.7500\n",
            "Epoch 41/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7988 - val_loss: 0.4767 - val_accuracy: 0.7500\n",
            "Epoch 42/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.8018 - val_loss: 0.4761 - val_accuracy: 0.7632\n",
            "Epoch 43/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7988 - val_loss: 0.4752 - val_accuracy: 0.7632\n",
            "Epoch 44/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7988 - val_loss: 0.4735 - val_accuracy: 0.7632\n",
            "Epoch 45/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.7974 - val_loss: 0.4709 - val_accuracy: 0.7632\n",
            "Epoch 46/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7974 - val_loss: 0.4708 - val_accuracy: 0.7632\n",
            "Epoch 47/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7974 - val_loss: 0.4685 - val_accuracy: 0.7632\n",
            "Epoch 48/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7974 - val_loss: 0.4687 - val_accuracy: 0.7632\n",
            "Epoch 49/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7988 - val_loss: 0.4674 - val_accuracy: 0.7632\n",
            "Epoch 50/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7988 - val_loss: 0.4661 - val_accuracy: 0.7632\n",
            "Epoch 51/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.8018 - val_loss: 0.4654 - val_accuracy: 0.7632\n",
            "Epoch 52/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.8018 - val_loss: 0.4661 - val_accuracy: 0.7632\n",
            "Epoch 53/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.8018 - val_loss: 0.4645 - val_accuracy: 0.7632\n",
            "Epoch 54/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.8018 - val_loss: 0.4641 - val_accuracy: 0.7632\n",
            "Epoch 55/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.8018 - val_loss: 0.4639 - val_accuracy: 0.7632\n",
            "Epoch 56/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.8018 - val_loss: 0.4632 - val_accuracy: 0.7632\n",
            "Epoch 57/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.8018 - val_loss: 0.4631 - val_accuracy: 0.7632\n",
            "Epoch 58/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.8018 - val_loss: 0.4610 - val_accuracy: 0.7632\n",
            "Epoch 59/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8018 - val_loss: 0.4602 - val_accuracy: 0.7632\n",
            "Epoch 60/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.8018 - val_loss: 0.4606 - val_accuracy: 0.7632\n",
            "Epoch 61/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.8018 - val_loss: 0.4622 - val_accuracy: 0.7632\n",
            "Epoch 62/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.8003 - val_loss: 0.4613 - val_accuracy: 0.7763\n",
            "Epoch 63/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.8003 - val_loss: 0.4610 - val_accuracy: 0.7763\n",
            "Epoch 64/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.8003 - val_loss: 0.4628 - val_accuracy: 0.7763\n",
            "Epoch 65/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.8003 - val_loss: 0.4618 - val_accuracy: 0.7763\n",
            "Epoch 66/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.8018 - val_loss: 0.4608 - val_accuracy: 0.7763\n",
            "Epoch 67/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.8018 - val_loss: 0.4593 - val_accuracy: 0.7763\n",
            "Epoch 68/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.8018 - val_loss: 0.4610 - val_accuracy: 0.7763\n",
            "Epoch 69/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8018 - val_loss: 0.4577 - val_accuracy: 0.7763\n",
            "Epoch 70/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8018 - val_loss: 0.4586 - val_accuracy: 0.7763\n",
            "Epoch 71/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8018 - val_loss: 0.4590 - val_accuracy: 0.7763\n",
            "Epoch 72/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.8018 - val_loss: 0.4605 - val_accuracy: 0.7763\n",
            "Epoch 73/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.8018 - val_loss: 0.4584 - val_accuracy: 0.7763\n",
            "Epoch 74/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.8003 - val_loss: 0.4609 - val_accuracy: 0.7632\n",
            "Epoch 75/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.8018 - val_loss: 0.4589 - val_accuracy: 0.7763\n",
            "Epoch 76/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.8018 - val_loss: 0.4591 - val_accuracy: 0.7632\n",
            "Epoch 77/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.8018 - val_loss: 0.4587 - val_accuracy: 0.7763\n",
            "Epoch 78/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8018 - val_loss: 0.4574 - val_accuracy: 0.7763\n",
            "Epoch 79/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.8003 - val_loss: 0.4572 - val_accuracy: 0.7763\n",
            "Epoch 80/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.8003 - val_loss: 0.4569 - val_accuracy: 0.7763\n",
            "Epoch 81/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.8003 - val_loss: 0.4567 - val_accuracy: 0.7763\n",
            "Epoch 82/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.8003 - val_loss: 0.4553 - val_accuracy: 0.7763\n",
            "Epoch 83/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.8003 - val_loss: 0.4571 - val_accuracy: 0.7763\n",
            "Epoch 84/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.8003 - val_loss: 0.4556 - val_accuracy: 0.7763\n",
            "Epoch 85/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.8003 - val_loss: 0.4555 - val_accuracy: 0.7763\n",
            "Epoch 86/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.8003 - val_loss: 0.4563 - val_accuracy: 0.7763\n",
            "Epoch 87/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.8003 - val_loss: 0.4565 - val_accuracy: 0.7763\n",
            "Epoch 88/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.8003 - val_loss: 0.4557 - val_accuracy: 0.7763\n",
            "Epoch 89/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8003 - val_loss: 0.4554 - val_accuracy: 0.7763\n",
            "Epoch 90/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8003 - val_loss: 0.4564 - val_accuracy: 0.7763\n",
            "Epoch 91/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7988 - val_loss: 0.4560 - val_accuracy: 0.7763\n",
            "Epoch 92/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8003 - val_loss: 0.4563 - val_accuracy: 0.7763\n",
            "Epoch 93/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7988 - val_loss: 0.4565 - val_accuracy: 0.7632\n",
            "Epoch 94/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7988 - val_loss: 0.4554 - val_accuracy: 0.7632\n",
            "Epoch 95/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8003 - val_loss: 0.4552 - val_accuracy: 0.7632\n",
            "Epoch 96/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8003 - val_loss: 0.4547 - val_accuracy: 0.7632\n",
            "Epoch 97/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7988 - val_loss: 0.4563 - val_accuracy: 0.7632\n",
            "Epoch 98/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8003 - val_loss: 0.4564 - val_accuracy: 0.7632\n",
            "Epoch 99/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.8003 - val_loss: 0.4579 - val_accuracy: 0.7632\n",
            "Epoch 100/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.8018 - val_loss: 0.4578 - val_accuracy: 0.7632\n",
            "Epoch 101/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.8003 - val_loss: 0.4588 - val_accuracy: 0.7632\n",
            "Epoch 102/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.8003 - val_loss: 0.4593 - val_accuracy: 0.7632\n",
            "Epoch 103/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8003 - val_loss: 0.4575 - val_accuracy: 0.7632\n",
            "Epoch 104/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.8003 - val_loss: 0.4574 - val_accuracy: 0.7632\n",
            "Epoch 105/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8003 - val_loss: 0.4590 - val_accuracy: 0.7632\n",
            "Epoch 106/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8003 - val_loss: 0.4586 - val_accuracy: 0.7632\n",
            "Epoch 107/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8003 - val_loss: 0.4573 - val_accuracy: 0.7632\n",
            "Epoch 108/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7988 - val_loss: 0.4582 - val_accuracy: 0.7632\n",
            "Epoch 109/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8003 - val_loss: 0.4588 - val_accuracy: 0.7632\n",
            "Epoch 110/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7988 - val_loss: 0.4580 - val_accuracy: 0.7632\n",
            "Epoch 111/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7988 - val_loss: 0.4584 - val_accuracy: 0.7632\n",
            "Epoch 112/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7988 - val_loss: 0.4572 - val_accuracy: 0.7632\n",
            "Epoch 113/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7988 - val_loss: 0.4573 - val_accuracy: 0.7632\n",
            "Epoch 114/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8018 - val_loss: 0.4607 - val_accuracy: 0.7632\n",
            "Epoch 115/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.8018 - val_loss: 0.4609 - val_accuracy: 0.7632\n",
            "Epoch 116/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7988 - val_loss: 0.4608 - val_accuracy: 0.7632\n",
            "Epoch 117/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7988 - val_loss: 0.4598 - val_accuracy: 0.7632\n",
            "Epoch 118/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.8003 - val_loss: 0.4594 - val_accuracy: 0.7632\n",
            "Epoch 119/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.8032 - val_loss: 0.4603 - val_accuracy: 0.7632\n",
            "Epoch 120/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8018 - val_loss: 0.4586 - val_accuracy: 0.7632\n",
            "Epoch 121/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.4589 - val_accuracy: 0.7632\n",
            "Epoch 122/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.8018 - val_loss: 0.4588 - val_accuracy: 0.7632\n",
            "Epoch 123/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.8032 - val_loss: 0.4596 - val_accuracy: 0.7632\n",
            "Epoch 124/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.4585 - val_accuracy: 0.7632\n",
            "Epoch 125/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.8032 - val_loss: 0.4592 - val_accuracy: 0.7632\n",
            "Epoch 126/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.4569 - val_accuracy: 0.7632\n",
            "Epoch 127/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8018 - val_loss: 0.4545 - val_accuracy: 0.7632\n",
            "Epoch 128/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.4569 - val_accuracy: 0.7632\n",
            "Epoch 129/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8018 - val_loss: 0.4549 - val_accuracy: 0.7632\n",
            "Epoch 130/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.4558 - val_accuracy: 0.7632\n",
            "Epoch 131/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.4572 - val_accuracy: 0.7632\n",
            "Epoch 132/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8003 - val_loss: 0.4552 - val_accuracy: 0.7632\n",
            "Epoch 133/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8003 - val_loss: 0.4535 - val_accuracy: 0.7632\n",
            "Epoch 134/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.4551 - val_accuracy: 0.7632\n",
            "Epoch 135/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.8003 - val_loss: 0.4555 - val_accuracy: 0.7632\n",
            "Epoch 136/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.8003 - val_loss: 0.4566 - val_accuracy: 0.7500\n",
            "Epoch 137/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8003 - val_loss: 0.4568 - val_accuracy: 0.7500\n",
            "Epoch 138/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.8018 - val_loss: 0.4578 - val_accuracy: 0.7500\n",
            "Epoch 139/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8003 - val_loss: 0.4572 - val_accuracy: 0.7500\n",
            "Epoch 140/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.8003 - val_loss: 0.4538 - val_accuracy: 0.7632\n",
            "Epoch 141/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8018 - val_loss: 0.4548 - val_accuracy: 0.7500\n",
            "Epoch 142/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.4569 - val_accuracy: 0.7500\n",
            "Epoch 143/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8018 - val_loss: 0.4583 - val_accuracy: 0.7500\n",
            "Epoch 144/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.4563 - val_accuracy: 0.7500\n",
            "Epoch 145/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.4558 - val_accuracy: 0.7500\n",
            "Epoch 146/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.8018 - val_loss: 0.4559 - val_accuracy: 0.7500\n",
            "Epoch 147/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.8032 - val_loss: 0.4575 - val_accuracy: 0.7500\n",
            "Epoch 148/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8032 - val_loss: 0.4566 - val_accuracy: 0.7500\n",
            "Epoch 149/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.8047 - val_loss: 0.4568 - val_accuracy: 0.7500\n",
            "Epoch 150/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.8047 - val_loss: 0.4564 - val_accuracy: 0.7500\n",
            "Epoch 151/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.8047 - val_loss: 0.4576 - val_accuracy: 0.7500\n",
            "Epoch 152/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.8047 - val_loss: 0.4569 - val_accuracy: 0.7500\n",
            "Epoch 153/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8047 - val_loss: 0.4563 - val_accuracy: 0.7632\n",
            "Epoch 154/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8062 - val_loss: 0.4576 - val_accuracy: 0.7500\n",
            "Epoch 155/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.8062 - val_loss: 0.4558 - val_accuracy: 0.7632\n",
            "Epoch 156/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.8062 - val_loss: 0.4557 - val_accuracy: 0.7632\n",
            "Epoch 157/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8047 - val_loss: 0.4569 - val_accuracy: 0.7500\n",
            "Epoch 158/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8106 - val_loss: 0.4584 - val_accuracy: 0.7500\n",
            "Epoch 159/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8106 - val_loss: 0.4592 - val_accuracy: 0.7500\n",
            "Epoch 160/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8076 - val_loss: 0.4580 - val_accuracy: 0.7500\n",
            "Epoch 161/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8091 - val_loss: 0.4563 - val_accuracy: 0.7500\n",
            "Epoch 162/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.8076 - val_loss: 0.4573 - val_accuracy: 0.7500\n",
            "Epoch 163/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.8076 - val_loss: 0.4546 - val_accuracy: 0.7632\n",
            "Epoch 164/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.8076 - val_loss: 0.4561 - val_accuracy: 0.7632\n",
            "Epoch 165/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.8091 - val_loss: 0.4565 - val_accuracy: 0.7632\n",
            "Epoch 166/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8120 - val_loss: 0.4580 - val_accuracy: 0.7632\n",
            "Epoch 167/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8091 - val_loss: 0.4561 - val_accuracy: 0.7632\n",
            "Epoch 168/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8106 - val_loss: 0.4582 - val_accuracy: 0.7632\n",
            "Epoch 169/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8120 - val_loss: 0.4589 - val_accuracy: 0.7632\n",
            "Epoch 170/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8135 - val_loss: 0.4572 - val_accuracy: 0.7632\n",
            "Epoch 171/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8106 - val_loss: 0.4558 - val_accuracy: 0.7632\n",
            "Epoch 172/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8120 - val_loss: 0.4572 - val_accuracy: 0.7632\n",
            "Epoch 173/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8120 - val_loss: 0.4564 - val_accuracy: 0.7632\n",
            "Epoch 174/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8120 - val_loss: 0.4569 - val_accuracy: 0.7632\n",
            "Epoch 175/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8120 - val_loss: 0.4546 - val_accuracy: 0.7632\n",
            "Epoch 176/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8076 - val_loss: 0.4542 - val_accuracy: 0.7632\n",
            "Epoch 177/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8106 - val_loss: 0.4542 - val_accuracy: 0.7632\n",
            "Epoch 178/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8091 - val_loss: 0.4554 - val_accuracy: 0.7632\n",
            "Epoch 179/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8135 - val_loss: 0.4557 - val_accuracy: 0.7632\n",
            "Epoch 180/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8106 - val_loss: 0.4539 - val_accuracy: 0.7632\n",
            "Epoch 181/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8120 - val_loss: 0.4537 - val_accuracy: 0.7632\n",
            "Epoch 182/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8120 - val_loss: 0.4539 - val_accuracy: 0.7632\n",
            "Epoch 183/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8106 - val_loss: 0.4532 - val_accuracy: 0.7632\n",
            "Epoch 184/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8106 - val_loss: 0.4509 - val_accuracy: 0.7632\n",
            "Epoch 185/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8106 - val_loss: 0.4518 - val_accuracy: 0.7632\n",
            "Epoch 186/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8135 - val_loss: 0.4527 - val_accuracy: 0.7632\n",
            "Epoch 187/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8106 - val_loss: 0.4493 - val_accuracy: 0.7632\n",
            "Epoch 188/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8120 - val_loss: 0.4525 - val_accuracy: 0.7632\n",
            "Epoch 189/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8150 - val_loss: 0.4518 - val_accuracy: 0.7632\n",
            "Epoch 190/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8150 - val_loss: 0.4506 - val_accuracy: 0.7632\n",
            "Epoch 191/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8150 - val_loss: 0.4491 - val_accuracy: 0.7632\n",
            "Epoch 192/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8135 - val_loss: 0.4499 - val_accuracy: 0.7632\n",
            "Epoch 193/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8150 - val_loss: 0.4514 - val_accuracy: 0.7500\n",
            "Epoch 194/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8164 - val_loss: 0.4515 - val_accuracy: 0.7500\n",
            "Epoch 195/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8150 - val_loss: 0.4488 - val_accuracy: 0.7632\n",
            "Epoch 196/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8135 - val_loss: 0.4492 - val_accuracy: 0.7632\n",
            "Epoch 197/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8135 - val_loss: 0.4477 - val_accuracy: 0.7632\n",
            "Epoch 198/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8135 - val_loss: 0.4473 - val_accuracy: 0.7632\n",
            "Epoch 199/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8135 - val_loss: 0.4469 - val_accuracy: 0.7632\n",
            "Epoch 200/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.8135 - val_loss: 0.4470 - val_accuracy: 0.7632\n",
            "Epoch 201/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8135 - val_loss: 0.4463 - val_accuracy: 0.7632\n",
            "Epoch 202/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8135 - val_loss: 0.4446 - val_accuracy: 0.7632\n",
            "Epoch 203/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8135 - val_loss: 0.4456 - val_accuracy: 0.7500\n",
            "Epoch 204/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8150 - val_loss: 0.4455 - val_accuracy: 0.7500\n",
            "Epoch 205/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8120 - val_loss: 0.4427 - val_accuracy: 0.7632\n",
            "Epoch 206/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8120 - val_loss: 0.4424 - val_accuracy: 0.7632\n",
            "Epoch 207/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8135 - val_loss: 0.4435 - val_accuracy: 0.7500\n",
            "Epoch 208/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8150 - val_loss: 0.4427 - val_accuracy: 0.7500\n",
            "Epoch 209/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8164 - val_loss: 0.4417 - val_accuracy: 0.7500\n",
            "Epoch 210/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8164 - val_loss: 0.4421 - val_accuracy: 0.7500\n",
            "Epoch 211/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8164 - val_loss: 0.4434 - val_accuracy: 0.7500\n",
            "Epoch 212/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8179 - val_loss: 0.4434 - val_accuracy: 0.7500\n",
            "Epoch 213/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8194 - val_loss: 0.4435 - val_accuracy: 0.7500\n",
            "Epoch 214/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8194 - val_loss: 0.4422 - val_accuracy: 0.7500\n",
            "Epoch 215/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8194 - val_loss: 0.4432 - val_accuracy: 0.7500\n",
            "Epoch 216/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8194 - val_loss: 0.4431 - val_accuracy: 0.7500\n",
            "Epoch 217/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8194 - val_loss: 0.4445 - val_accuracy: 0.7500\n",
            "Epoch 218/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8194 - val_loss: 0.4444 - val_accuracy: 0.7500\n",
            "Epoch 219/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8194 - val_loss: 0.4413 - val_accuracy: 0.7500\n",
            "Epoch 220/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8179 - val_loss: 0.4419 - val_accuracy: 0.7500\n",
            "Epoch 221/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8179 - val_loss: 0.4419 - val_accuracy: 0.7500\n",
            "Epoch 222/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8194 - val_loss: 0.4415 - val_accuracy: 0.7500\n",
            "Epoch 223/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8179 - val_loss: 0.4417 - val_accuracy: 0.7500\n",
            "Epoch 224/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.8179 - val_loss: 0.4415 - val_accuracy: 0.7500\n",
            "Epoch 225/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8179 - val_loss: 0.4412 - val_accuracy: 0.7500\n",
            "Epoch 226/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8179 - val_loss: 0.4388 - val_accuracy: 0.7500\n",
            "Epoch 227/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8179 - val_loss: 0.4406 - val_accuracy: 0.7500\n",
            "Epoch 228/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8179 - val_loss: 0.4409 - val_accuracy: 0.7500\n",
            "Epoch 229/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8179 - val_loss: 0.4403 - val_accuracy: 0.7500\n",
            "Epoch 230/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8179 - val_loss: 0.4380 - val_accuracy: 0.7632\n",
            "Epoch 231/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8179 - val_loss: 0.4397 - val_accuracy: 0.7500\n",
            "Epoch 232/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8179 - val_loss: 0.4392 - val_accuracy: 0.7632\n",
            "Epoch 233/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8194 - val_loss: 0.4375 - val_accuracy: 0.7632\n",
            "Epoch 234/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8179 - val_loss: 0.4387 - val_accuracy: 0.7632\n",
            "Epoch 235/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8194 - val_loss: 0.4375 - val_accuracy: 0.7632\n",
            "Epoch 236/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8194 - val_loss: 0.4384 - val_accuracy: 0.7632\n",
            "Epoch 237/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8194 - val_loss: 0.4374 - val_accuracy: 0.7632\n",
            "Epoch 238/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8179 - val_loss: 0.4377 - val_accuracy: 0.7632\n",
            "Epoch 239/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8209 - val_loss: 0.4376 - val_accuracy: 0.7632\n",
            "Epoch 240/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8179 - val_loss: 0.4375 - val_accuracy: 0.7632\n",
            "Epoch 241/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8194 - val_loss: 0.4385 - val_accuracy: 0.7500\n",
            "Epoch 242/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8194 - val_loss: 0.4374 - val_accuracy: 0.7632\n",
            "Epoch 243/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8209 - val_loss: 0.4375 - val_accuracy: 0.7632\n",
            "Epoch 244/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8194 - val_loss: 0.4381 - val_accuracy: 0.7632\n",
            "Epoch 245/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8209 - val_loss: 0.4385 - val_accuracy: 0.7632\n",
            "Epoch 246/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8209 - val_loss: 0.4387 - val_accuracy: 0.7632\n",
            "Epoch 247/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8194 - val_loss: 0.4373 - val_accuracy: 0.7632\n",
            "Epoch 248/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8194 - val_loss: 0.4370 - val_accuracy: 0.7632\n",
            "Epoch 249/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8194 - val_loss: 0.4363 - val_accuracy: 0.7632\n",
            "Epoch 250/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8194 - val_loss: 0.4362 - val_accuracy: 0.7632\n",
            "Epoch 251/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8194 - val_loss: 0.4359 - val_accuracy: 0.7632\n",
            "Epoch 252/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8209 - val_loss: 0.4329 - val_accuracy: 0.7632\n",
            "Epoch 253/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8209 - val_loss: 0.4331 - val_accuracy: 0.7632\n",
            "Epoch 254/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8209 - val_loss: 0.4337 - val_accuracy: 0.7632\n",
            "Epoch 255/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8238 - val_loss: 0.4341 - val_accuracy: 0.7632\n",
            "Epoch 256/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8238 - val_loss: 0.4333 - val_accuracy: 0.7632\n",
            "Epoch 257/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8223 - val_loss: 0.4345 - val_accuracy: 0.7632\n",
            "Epoch 258/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8223 - val_loss: 0.4345 - val_accuracy: 0.7632\n",
            "Epoch 259/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8223 - val_loss: 0.4343 - val_accuracy: 0.7632\n",
            "Epoch 260/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8209 - val_loss: 0.4337 - val_accuracy: 0.7632\n",
            "Epoch 261/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8209 - val_loss: 0.4324 - val_accuracy: 0.7632\n",
            "Epoch 262/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8194 - val_loss: 0.4333 - val_accuracy: 0.7632\n",
            "Epoch 263/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8150 - val_loss: 0.4331 - val_accuracy: 0.7632\n",
            "Epoch 264/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8164 - val_loss: 0.4313 - val_accuracy: 0.7763\n",
            "Epoch 265/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8150 - val_loss: 0.4310 - val_accuracy: 0.7763\n",
            "Epoch 266/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8223 - val_loss: 0.4311 - val_accuracy: 0.7895\n",
            "Epoch 267/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8238 - val_loss: 0.4311 - val_accuracy: 0.7895\n",
            "Epoch 268/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8238 - val_loss: 0.4309 - val_accuracy: 0.7895\n",
            "Epoch 269/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8209 - val_loss: 0.4324 - val_accuracy: 0.7895\n",
            "Epoch 270/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8238 - val_loss: 0.4331 - val_accuracy: 0.7895\n",
            "Epoch 271/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8223 - val_loss: 0.4333 - val_accuracy: 0.7895\n",
            "Epoch 272/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8179 - val_loss: 0.4319 - val_accuracy: 0.7895\n",
            "Epoch 273/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8179 - val_loss: 0.4309 - val_accuracy: 0.7895\n",
            "Epoch 274/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8194 - val_loss: 0.4321 - val_accuracy: 0.7895\n",
            "Epoch 275/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8209 - val_loss: 0.4329 - val_accuracy: 0.7895\n",
            "Epoch 276/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8194 - val_loss: 0.4335 - val_accuracy: 0.7895\n",
            "Epoch 277/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8209 - val_loss: 0.4326 - val_accuracy: 0.7895\n",
            "Epoch 278/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8194 - val_loss: 0.4331 - val_accuracy: 0.7895\n",
            "Epoch 279/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8194 - val_loss: 0.4311 - val_accuracy: 0.7895\n",
            "Epoch 280/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8179 - val_loss: 0.4310 - val_accuracy: 0.7895\n",
            "Epoch 281/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8179 - val_loss: 0.4304 - val_accuracy: 0.7895\n",
            "Epoch 282/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.8194 - val_loss: 0.4307 - val_accuracy: 0.7895\n",
            "Epoch 283/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8209 - val_loss: 0.4308 - val_accuracy: 0.7895\n",
            "Epoch 284/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8209 - val_loss: 0.4300 - val_accuracy: 0.7895\n",
            "Epoch 285/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8209 - val_loss: 0.4302 - val_accuracy: 0.7895\n",
            "Epoch 286/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8209 - val_loss: 0.4315 - val_accuracy: 0.7895\n",
            "Epoch 287/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8223 - val_loss: 0.4313 - val_accuracy: 0.7895\n",
            "Epoch 288/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8238 - val_loss: 0.4317 - val_accuracy: 0.7895\n",
            "Epoch 289/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8223 - val_loss: 0.4290 - val_accuracy: 0.7895\n",
            "Epoch 290/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8223 - val_loss: 0.4287 - val_accuracy: 0.7895\n",
            "Epoch 291/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8253 - val_loss: 0.4281 - val_accuracy: 0.7895\n",
            "Epoch 292/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8267 - val_loss: 0.4279 - val_accuracy: 0.7895\n",
            "Epoch 293/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8253 - val_loss: 0.4283 - val_accuracy: 0.7895\n",
            "Epoch 294/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8223 - val_loss: 0.4291 - val_accuracy: 0.7895\n",
            "Epoch 295/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8223 - val_loss: 0.4293 - val_accuracy: 0.7895\n",
            "Epoch 296/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8223 - val_loss: 0.4291 - val_accuracy: 0.7895\n",
            "Epoch 297/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8223 - val_loss: 0.4289 - val_accuracy: 0.7895\n",
            "Epoch 298/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8223 - val_loss: 0.4284 - val_accuracy: 0.7895\n",
            "Epoch 299/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8209 - val_loss: 0.4296 - val_accuracy: 0.7895\n",
            "Epoch 300/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8238 - val_loss: 0.4285 - val_accuracy: 0.7895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "metrics = pd.DataFrame(history.history)\n",
        "metrics.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iLhTD3gt7tv6",
        "outputId": "468b6909-ff48-4028-afd8-3fb009efb60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         loss  accuracy  val_loss  val_accuracy\n",
              "295  0.408652  0.822320  0.429130      0.789474\n",
              "296  0.408590  0.822320  0.428873      0.789474\n",
              "297  0.408727  0.822320  0.428361      0.789474\n",
              "298  0.408705  0.820852  0.429576      0.789474\n",
              "299  0.408784  0.823789  0.428488      0.789474"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b76b9996-87e5-4760-918c-e09ac7bb33b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>0.408652</td>\n",
              "      <td>0.822320</td>\n",
              "      <td>0.429130</td>\n",
              "      <td>0.789474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.408590</td>\n",
              "      <td>0.822320</td>\n",
              "      <td>0.428873</td>\n",
              "      <td>0.789474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>0.408727</td>\n",
              "      <td>0.822320</td>\n",
              "      <td>0.428361</td>\n",
              "      <td>0.789474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.408705</td>\n",
              "      <td>0.820852</td>\n",
              "      <td>0.429576</td>\n",
              "      <td>0.789474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0.408784</td>\n",
              "      <td>0.823789</td>\n",
              "      <td>0.428488</td>\n",
              "      <td>0.789474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b76b9996-87e5-4760-918c-e09ac7bb33b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b76b9996-87e5-4760-918c-e09ac7bb33b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b76b9996-87e5-4760-918c-e09ac7bb33b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics[['loss', 'val_loss']].plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "TtgAstCpCZz8",
        "outputId": "a351366c-dcce-46e8-f3f7-58d5562caedd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coqn-50LDIac",
        "outputId": "7b0c9d52-c607-4dea-d3fc-583cdbdebdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86        76\n",
            "           1       0.86      0.72      0.79        58\n",
            "\n",
            "    accuracy                           0.83       134\n",
            "   macro avg       0.83      0.82      0.82       134\n",
            "weighted avg       0.83      0.83      0.83       134\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.test.is_gpu_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3opv5FzE_5K",
        "outputId": "345e036e-a78c-406f-fd24-a4ead99aaa71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-32-de130dd510b0>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkcFecRkGHuw",
        "outputId": "4ab154da-8008-4522-b892-038d05ca0885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save(\"nn_titanic\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jwGKss-GWap",
        "outputId": "3768865e-6a5a-4028-f451-104a6ef10095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: nn_titanic/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_titanic = load_model(\"nn_titanic\")"
      ],
      "metadata": {
        "id": "4Bm6n2snHy7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_model = model_titanic.predict(X_test)"
      ],
      "metadata": {
        "id": "UNRxlxbsIHTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_titanic.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hSRuN60IKQ1",
        "outputId": "9573c019-641c-4ade-cd75-aeca3efa23c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37\n",
            "Trainable params: 37\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# 0 - 255\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUV1J5KJI5um",
        "outputId": "f15b7068-627f-431a-aef7-fac1f2fc3b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_image(image):\n",
        "  plt.imshow(image, cmap='binary')"
      ],
      "metadata": {
        "id": "bQzEeMBiKCed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(X_train[100])\n",
        "print(y_train[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "y4G5oaIxKU3L",
        "outputId": "5ce0dd9c-30d9-4b7c-dc73-6097340df808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=46)"
      ],
      "metadata": {
        "id": "2VM6Y0d5KX-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TN7ktFZKzZU",
        "outputId": "b5163c07-e3dd-4e98-dad5-f83253cf4e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# siapkan label dengan One Hot Encoding (wajib untuk multiclass)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_ohe = to_categorical(y_train)\n",
        "y_val_ohe = to_categorical(y_val)\n",
        "y_test_ohe = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "QQdEJ_CoK3tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSd54QmyNEyi",
        "outputId": "4e77ae31-90cc-4efe-95b2-4e50de626660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# funtional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "contoh model sequential dengan arsitektur yang sama\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(32, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\"\"\"\n",
        "# deklarasikan arsitektur\n",
        "data_in = Input(shape=(28,28))\n",
        "data_flat = Flatten()(data_in)\n",
        "data_drop = Dropout(0.25)(data_flat)\n",
        "hidden_1 = Dense(256, activation='elu')(data_drop)\n",
        "hidden_drop = Dropout(0.25)(hidden_1)\n",
        "hidden_2 = Dense(32, activation='elu')(hidden_drop)\n",
        "hidden_drop_2 = Dropout(0.25)(hidden_2)\n",
        "out = Dense(10, activation='softmax')(hidden_drop_2)\n",
        "\n",
        "model = Model(inputs=data_in, outputs=out)\n",
        "\n",
        "# compile\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', # paling modern\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train\n",
        "history = model.fit(X_train, y_train_ohe, epochs=30, validation_data=(X_val, y_val_ohe))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r03TNubQL6LD",
        "outputId": "dfa38ecd-da58-4617-d817-4fc1cb81de03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1688/1688 [==============================] - 8s 4ms/step - loss: 0.4638 - accuracy: 0.8580 - val_loss: 0.1826 - val_accuracy: 0.9438\n",
            "Epoch 2/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2787 - accuracy: 0.9155 - val_loss: 0.1197 - val_accuracy: 0.9625\n",
            "Epoch 3/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2231 - accuracy: 0.9336 - val_loss: 0.0932 - val_accuracy: 0.9723\n",
            "Epoch 4/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1950 - accuracy: 0.9417 - val_loss: 0.0869 - val_accuracy: 0.9750\n",
            "Epoch 5/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1727 - accuracy: 0.9475 - val_loss: 0.0866 - val_accuracy: 0.9727\n",
            "Epoch 6/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1585 - accuracy: 0.9516 - val_loss: 0.0689 - val_accuracy: 0.9785\n",
            "Epoch 7/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1457 - accuracy: 0.9565 - val_loss: 0.0695 - val_accuracy: 0.9792\n",
            "Epoch 8/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1356 - accuracy: 0.9587 - val_loss: 0.0653 - val_accuracy: 0.9782\n",
            "Epoch 9/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1292 - accuracy: 0.9615 - val_loss: 0.0621 - val_accuracy: 0.9798\n",
            "Epoch 10/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1234 - accuracy: 0.9629 - val_loss: 0.0659 - val_accuracy: 0.9802\n",
            "Epoch 11/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1151 - accuracy: 0.9651 - val_loss: 0.0600 - val_accuracy: 0.9832\n",
            "Epoch 12/30\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1107 - accuracy: 0.9660 - val_loss: 0.0575 - val_accuracy: 0.9823\n",
            "Epoch 13/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1043 - accuracy: 0.9678 - val_loss: 0.0593 - val_accuracy: 0.9817\n",
            "Epoch 14/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1023 - accuracy: 0.9698 - val_loss: 0.0623 - val_accuracy: 0.9818\n",
            "Epoch 15/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0983 - accuracy: 0.9695 - val_loss: 0.0568 - val_accuracy: 0.9840\n",
            "Epoch 16/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1004 - accuracy: 0.9691 - val_loss: 0.0536 - val_accuracy: 0.9832\n",
            "Epoch 17/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0952 - accuracy: 0.9708 - val_loss: 0.0574 - val_accuracy: 0.9820\n",
            "Epoch 18/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0948 - accuracy: 0.9708 - val_loss: 0.0551 - val_accuracy: 0.9848\n",
            "Epoch 19/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0894 - accuracy: 0.9726 - val_loss: 0.0490 - val_accuracy: 0.9860\n",
            "Epoch 20/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0861 - accuracy: 0.9731 - val_loss: 0.0598 - val_accuracy: 0.9817\n",
            "Epoch 21/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0863 - accuracy: 0.9731 - val_loss: 0.0497 - val_accuracy: 0.9858\n",
            "Epoch 22/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0815 - accuracy: 0.9745 - val_loss: 0.0599 - val_accuracy: 0.9820\n",
            "Epoch 23/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0841 - accuracy: 0.9741 - val_loss: 0.0576 - val_accuracy: 0.9833\n",
            "Epoch 24/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0834 - accuracy: 0.9740 - val_loss: 0.0468 - val_accuracy: 0.9867\n",
            "Epoch 25/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0783 - accuracy: 0.9762 - val_loss: 0.0493 - val_accuracy: 0.9853\n",
            "Epoch 26/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0806 - accuracy: 0.9753 - val_loss: 0.0477 - val_accuracy: 0.9858\n",
            "Epoch 27/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0779 - accuracy: 0.9751 - val_loss: 0.0518 - val_accuracy: 0.9853\n",
            "Epoch 28/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0766 - accuracy: 0.9756 - val_loss: 0.0477 - val_accuracy: 0.9858\n",
            "Epoch 29/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0726 - accuracy: 0.9772 - val_loss: 0.0468 - val_accuracy: 0.9847\n",
            "Epoch 30/30\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0739 - accuracy: 0.9764 - val_loss: 0.0466 - val_accuracy: 0.9862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nayKGJp6Oq3J",
        "outputId": "83a84ec4-2178-4a35-d6da-22d5f52de71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 32)                8224      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,514\n",
            "Trainable params: 209,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "metrics = pd.DataFrame(history.history)\n",
        "metrics[['loss', 'val_loss']].plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XqWtAUeOUpKm",
        "outputId": "fe144626-2f4e-4319-dcc5-8d6f0b630b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wc9Z3/8dd3i7TqvcuyZGPcJGMb2WDApuRCC8FHCKGGcgkkhBoIFy6V8COXHM6R9uPC5XKEkEBsx0AwJRBIDMZAwLItW+5FbmpW71qttPu9P2ZlyUayJGut0cx+no/HPraNZj/jhffMfr/f+Y7SWiOEEMIeHGYXIIQQInQk1IUQwkYk1IUQwkYk1IUQwkYk1IUQwkZcZn1wamqqzs/PN+vjhRDCkjZs2FCvtU4b6n3TQj0/P5+SkhKzPl4IISxJKXXwRO9L84sQQtiIhLoQQtiIhLoQQtiIaW3qQojw1NPTQ0VFBV6v1+xSJjSPx0Nubi5ut3tUfyehLoQYVxUVFcTFxZGfn49SyuxyJiStNQ0NDVRUVFBQUDCqv5XmFyHEuPJ6vaSkpEign4BSipSUlJP6NSOhLoQYdxLowzvZfyPLhXrJgUb+442dyJTBQgjxSZYL9S0VLfzqnX00dfaYXYoQwqJiY2PNLuGUsVyo5yRFAVDZ1GVyJUIIMfFYL9QTg6HeLKEuhBgbrTUPPfQQhYWFFBUVsWLFCgCqq6tZsmQJc+fOpbCwkPfeew+/38+tt956dNmf/vSnJlc/OMsNaZRQF8I+fvDKNrZXtYZ0nbOy4/n+Z2ePaNkXX3yR0tJSNm/eTH19PQsWLGDJkiU8//zzXHLJJXz729/G7/fT2dlJaWkplZWVbN26FYDm5uaQ1h0qljtST4x2Ex3hlOYXIcSYrVu3juuvvx6n00lGRgbnn38+69evZ8GCBfz2t7/lkUceoaysjLi4OKZMmUJ5eTn33HMPb7zxBvHx8WaXPyjLHakrpchOjKJKjtSFsLyRHlGPtyVLlrB27Vpee+01br31Vh544AFuvvlmNm/ezJtvvslTTz3FypUrefrpp80u9RMsd6QORhOMNL8IIcZq8eLFrFixAr/fT11dHWvXrmXhwoUcPHiQjIwMbr/9dr785S+zceNG6uvrCQQCXH311Tz22GNs3LjR7PIHZbkjdYDsxCjKKlvMLkMIYXFXXXUVH374IWeccQZKKR5//HEyMzP53e9+x7Jly3C73cTGxvLss89SWVnJbbfdRiAQAOBHP/qRydUPzpKhnpsURWOHjy6fn6gIp9nlCCEspr29HTCac5ctW8ayZcuOef+WW27hlltu+cTfTdSj84Es2/wCMgJGCCGOZ8lQz5ZQF0KIQVky1PvOKpURMEIIcSxLhnpGXCROh5Kx6kIIcRxLhrrL6SAz3iPNL0IIcRxLhjrIWHUhhBiMZUM9O9EjzS9CCHEcy4Z6TlIUNa1e/AG5WIYQ4tQ50dzrBw4coLCwcByrGZ51Qz0xGn9Ac6RVrkguhBB9LHlGKRjNL2CMVe8bty6EsJi/PAw1ZaFdZ2YRXPbjId9++OGHmTRpEnfddRcAjzzyCC6XizVr1tDU1ERPTw+PPfYYS5cuHdXHer1e7rzzTkpKSnC5XDzxxBNceOGFbNu2jdtuuw2fz0cgEOCFF14gOzubL3zhC1RUVOD3+/nud7/LtddeO6bN7mPZUM+VsepCiJNw7bXXcv/99x8N9ZUrV/Lmm29y7733Eh8fT319PWeffTZXXnnlqC7+/OSTT6KUoqysjJ07d3LxxReze/dunnrqKe677z5uvPFGfD4ffr+f119/nezsbF577TUAWlpCN5eVZUO97+i8QjpLhbCuExxRnyrz5s2jtraWqqoq6urqSEpKIjMzk69//eusXbsWh8NBZWUlR44cITMzc8TrXbduHffccw8AM2bMYPLkyezevZtFixbxwx/+kIqKCj73uc8xbdo0ioqKePDBB/nmN7/JFVdcweLFi0O2fZZtU4+OcJEU7ZZhjUKIUbvmmmtYtWoVK1as4Nprr+W5556jrq6ODRs2UFpaSkZGBl5vaPrrbrjhBlavXk1UVBSXX345f//73zn99NPZuHEjRUVFfOc73+HRRx8NyWeBhY/UwRgBI80vQojRuvbaa7n99tupr6/n3XffZeXKlaSnp+N2u1mzZg0HDx4c9ToXL17Mc889x0UXXcTu3bs5dOgQ06dPp7y8nClTpnDvvfdy6NAhtmzZwowZM0hOTuamm24iMTGR3/zmNyHbNmuHemIU5XUdZpchhLCY2bNn09bWRk5ODllZWdx444189rOfpaioiOLiYmbMmDHqdX7ta1/jzjvvpKioCJfLxTPPPENkZCQrV67k97//PW63m8zMTL71rW+xfv16HnroIRwOB263m1/96lch2zaltTnjvIuLi3VJScmY1vGDV7axYv1htv3gklF1aAghzLNjxw5mzpxpdhmWMNi/lVJqg9a6eKi/sWybOhhH6p0+Py1dPWaXIoQQE4Llm1/AGAGTGB1hcjVCCLsqKyvji1/84jGvRUZG8tFHH5lU0dBGFOpKqUuBnwNO4Dda60HHISmlrgZWAQu01mNrWxmBgfOqF+YknOqPE0KEiNbaUk2mRUVFlJaWjutnnmzT+LDNL0opJ/AkcBkwC7heKTVrkOXigPuAcdt1yWXthLAej8dDQ0PDSYdWONBa09DQgMfjGfXfjuRIfSGwV2tdDqCUWg4sBbYft9z/A/4DeGjUVZyk5JgIPG6HzNYohIXk5uZSUVFBXV2d2aVMaB6Ph9zc3FH/3UhCPQc4POB5BXDWwAWUUvOBSVrr15RSQ4a6UuoO4A6AvLy8URc7yPrIToyiqkVCXQircLvdFBQUmF2GbY159ItSygE8ATw43LJa619rrYu11sVpaWlj/WggeLEMOVIXQghgZKFeCUwa8Dw3+FqfOKAQeEcpdQA4G1itlBpyHGUoyRWQhBCi30hCfT0wTSlVoJSKAK4DVve9qbVu0Vqnaq3ztdb5wD+AK8dj9AsYoV7f7sPb4x+PjxNCiAlt2FDXWvcCdwNvAjuAlVrrbUqpR5VSV57qAofTN1ujzAEjhBAjHKeutX4deP241743xLIXjL2skesbq17Z3MWUtKEvOyWEEOHA0tMEQP9YdTlSF0IIG4R6ZoIHh0JGwAghBDYIdbfTQUa8h8pmuQC1EEJYPtShb1hjp9llCCGE6WwR6tkyVl0IIQCbhHpOUhQ1LV78AZkgSAgR3mwR6tmJUfT4NXVt3WaXIoQQprJFqOcenYJX2tWFEOHNFqHefwKSjIARQoQ3W4R631QBMlZdCBHubBHqsZEuEqLc0vwihAh7tgh1MMaqV0nzixAizNkm1LPlYhlCCGGfUM9NMk5AkovZCiHCmW1CPTvRQ3t3L63eXrNLEUII09gm1HMSowEZASOECG/2CfUkmVddCCFsE+rZiR4AmdhLCBHWbBPqqTGRRLgcEupCiLBmm1B3OFRwXnUJdSFE+LJNqIPRBCMdpUKIcGarUJcjdSFEuLNVqGcnRlHX1k13r9/sUoQQwhS2CvWc4GyN1TIHjBAiTNkr1I/Oqy5NMEKI8GSvUE+UUBdChDdbhXpWQhRKyVQBQojwZatQj3A5SI+LlKkChBBhy1ahDsF51SXUhRBhynahLmPVhRDhzJahXt3sJRCQi2UIIcKP/UI9KQqfP0B9e7fZpQghxLizX6gHhzVWSBOMECIM2S7UsxPlYhlCiPBlu1A/elapjFUXQoQh24V6vMdNnMclI2CEEGHJdqEORru6NL8IIcKRbUO9QppfhBBhyJ6hniRH6kKI8DSiUFdKXaqU2qWU2quUeniQ97+qlCpTSpUqpdYppWaFvtSRy06MotXbS5u3x8wyhBBi3A0b6kopJ/AkcBkwC7h+kNB+XmtdpLWeCzwOPBHySkdBpuAVQoSrkRypLwT2aq3LtdY+YDmwdOACWuvWAU9jAFPP0Zex6kKIcOUawTI5wOEBzyuAs45fSCl1F/AAEAFcNNiKlFJ3AHcA5OXljbbWEcuVsepCiDAVso5SrfWTWuupwDeB7wyxzK+11sVa6+K0tLRQffQnpMVG4nYqmSpACBF2RhLqlcCkAc9zg68NZTnwz2MpaqwcDkVWQhRVcgFqIUSYGUmorwemKaUKlFIRwHXA6oELKKWmDXj6GWBP6Eo8OTmJUVQ2dZpdhhBCjKth29S11r1KqbuBNwEn8LTWeptS6lGgRGu9GrhbKfVPQA/QBNxyKoseiZykKN7bU2d2GUIIMa5G0lGK1vp14PXjXvvegMf3hbiuMctOjKK2rRtfb4AIly3PsRJCiE+wbdrlJkahNdS0SLu6ECJ82DbUs49eLEPa1YUQ4cO2od43r7qMgBFChBPbhnpWggeAw41ypC6ECB+2DXWP20lhTjxvbqtBa1NnLRBCiHFj21AHuG5BHjtr2ig93Gx2KUIIMS5sHepL52YT5Xbyx48PmV2KEEKMC1uHepzHzZVnZPPK5mqZW10IERZsHeoA15+VR1ePn5dLq8wuRQghTjnbh/oZuQnMzIrn+Y8OSYepEML2bB/qSiluWDiJ7dWtlFW2mF2OEEKcUrYPdYCl83LwuB3SYSqEsL2wCPV4j5vPzsnm5dIq2rt7zS5HCCFOmbAIdTA6TDt9flZLh6kQwsbCJtTnTUpkRmacNMEIIWwtbEJdKcX1C/Moq2yhrEI6TIUQ9hQ2oQ7wz/NyiHQ5+ON6OVoXQthTWIV6QpSbK+Zk8/KmSjqkw1QIYUNhFeoA1y+cRIfPzyubpcNUCGE/YRfqZ05OYlp6rHSYCiFsKexCva/DdHNFC9uqpMNUCGEvYRfqAJ+bn0OEy8Hyjw+bXYoQQoRUWIZ6YnQEnynK4s+bKun0SYepEMI+wjLUAa5fmEdbdy+vbqk2uxQhhAiZsA31BflJTE2LkQ5TIYSthG2o93WYbjrUzI7qVrPLEUKIkAjbUAe4en4uEU4Hy+VoXQhhE2Ed6kkxEVxWlMmLmyrp8vnNLkcIIcYsrEMdgh2m3l5eK5MOUyGE9YV9qJ9VkMyU1Bie/+ig2aUIIcSYhX2oK6X44qLJbDzULG3rQgjLC/tQB7h5UT6Lp6XyvZe3UXq42exyhBDipEmoA06H4hfXzSM9PpI7/7CB+vZus0sSQoiTIqEelBQTwVM3nUljh497nt9Erz9gdklCCDFqEuoDFOYk8O9XFfFheQOPv7nL7HKEEGLUXGYXMNFcfWYumyua+fXacubkJnDFnGyzSxJCiBGTI/VBfOczszhzchL/umoLu4+0mV2OEEKMmIT6ICJcDv7rxvnERLr4yu830OrtMbskIYQYkRGFulLqUqXULqXUXqXUw4O8/4BSartSaotS6m9KqcmhL3V8ZcR7+K8b53O4sZMHVmwmENBmlySEEMMaNtSVUk7gSeAyYBZwvVJq1nGLbQKKtdZzgFXA46Eu1AwL8pP57hWzeHvHEZ5cs9fscoQQYlgjOVJfCOzVWpdrrX3AcmDpwAW01mu01p3Bp/8AckNbpnluXjSZq+bl8MTbu1mzq9bscoQQ4oRGEuo5wMCLeVYEXxvKl4C/DPaGUuoOpVSJUqqkrq5u5FWaSCnFv19VxIzMeO5fXsqhhs7h/0gIIUwS0o5SpdRNQDGwbLD3tda/1loXa62L09LSQvnRp1RUhJP/vulMAL7yhw0yTa8QYsIaSahXApMGPM8NvnYMpdQ/Ad8GrtRa2+48+7yUaH5+3Vx21rRyzx834uuVM06FEBPPSEJ9PTBNKVWglIoArgNWD1xAKTUP+G+MQLdtw/MF09N5dGkhb++o5a7nJdiFEBPPsKGute4F7gbeBHYAK7XW25RSjyqlrgwutgyIBf6klCpVSq0eYnWW98WzJ/Po0tm8tf0Idz+/kR6ZI0YIMYEorc0Zf11cXKxLSkpM+exQeOb9/TzyynYunZ3JL2+Yh9sp53EJIU49pdQGrXXxUO9LEp2kW88t4HtXzOKNbTXc+8dNcsQuhJgQrBfq3W2w929mVwHAv5xXwHc+M5O/bK3h/uWlMl2vEMJ01gv1D34Jz30e2mrMrgSALy+ewrcvn8lrZdXcv0KCXQhhLuuFeuHVoAOw7SWzKznq9iVT+LfLZvDqlmq+vnKzBLsQwjTWC/W06ZA5B8r+ZHYlx/jK+VP55qUzeGVzFQ/+aTN+mQBMCGEC64U6QNE1ULkBGvaZXckx7rxgKg9dMp2XS6v4hgS7EMIE1gz1wqsBBWWrzK7kE+668DS+cfHpvLSpkgdXltLp6zW7JCFEGLFmqCfkQP55RhOMSePsT+Tui6bxjYtP58+lVVzys7Ws3W2NycuEENZnzVAHKPo8NOyB6s1mVzKouy+axoo7zsbtcHDz0x/zwMpSmjp8ZpclhLA564b6zCvB4Z5wHaYDnTUlhdfvW8w9F53G6tIq/umJd3m5tBKzzuIVQtifdUM9OhmmXQxbX4DAxJ0K1+N28uDF03n13vPITY7mvuWl3PbMeiqaZF52IUToWTfUwWiCaauGg++bXcmwZmTG8+Kd5/D9z87i4/2NXPzTtTy9br+MkBFChJS1Q/30SyEidkI3wQzkdChuO7eAv359CQsLknn01e187lcfsLOm1ezShBA2Ye1Qj4iGGVfA9peh1zrX5chNiua3ty7g59fN5XBjJ1f8Yh0/en0Hbd4es0sTQlictUMdYM414G2BPW+ZXcmoKKVYOjeHtx84n6vm5fDfa8u58CfvsnL9YQLSJCOEOEnWD/WCCyA61TJNMMdLjolg2TVn8PJd5zI5JZp/fWELVz65jvUHGs0uTQhhQdYPdacLCj8Hu98Ar3Xbps+YlMiqry7i59fNpaHdxzVPfcjdz2+ksrnL7NKEEBZi/VAHKPoC9Hph56tmVzImfU0yf3vwfO771DTe3nGEi37yDk+8tVumGxBCjIg9Qj23GBInW7YJ5njRES6+/unT+duDF3Dx7Ex+8bc9XPQTOXFJCDE8e4S6UsbMjeXvQHut2dWETE5iFL+8fh5/+uoiUuMiuG95KVf91we8tf2IdKYKIQZlj1AHI9R1ALa+aHYlIbcgP5nVd53H41fPoa6tm9ufLeHTP32X5R8fwtszcc+mFUKMP2XWz/ni4mJdUlIS2pU+dR44I+H2iXEN01Oh1x/gtbJqfr22nG1VraTGRnLbufncdNZkEqLdZpcnhDjFlFIbtNbFQ71vnyN1CF48owQay82u5JRxOR0snZvDq/ecxx++dBYzs+JY9uYuFv34bzz6ynaZU0aIMGevUC+82rgve8HcOsaBUorzpqXy+y+dxev3LuaS2Zk8++EBzl/2Dvct38S2qhazSxRCmMBezS8Av70cOurgro+NDtQwUtXcxdPr9vPHjw/R4fMzKyueC6anceGMdOZNSsTltNc+XIhwNFzzi/1CveS38Or98JW1kHVG6NdvAS1dPfyp5DB/3X6EDQeb8Ac08R4XS05P48Lp6Zw/PY3U2EizyxRCnITwC/XORvjJ6XD2V+Hix0K/fotp6erh/b31rNlZy5pdddS3GxOfnZGbwPnT07lwehpzchNxOsLrV40QVhV+oQ7w/HXGZe6+vg0c0uTQJxDQbK9uDQZ8LZsON6M1JEW7WTQ1hXOmpnLuaankp0SjwqzpSgirGC7UXeNZzLgp+jzs/otx8YyCxWZXM2E4HIrCnAQKcxK451PTaOrwsXZPHe/uruPDfQ28XlYDQHaCh3NOS+WcqSmce1oqGfEekysXQoyUPUN9+uXgjjGmDZBQH1JSTARL5+awdG4OWmv213fw/r4GPthbz9s7jrBqQwUAU9NiOPe0VM6ZmsriaanERNrzPxsh7MCezS8AL94Bu9+Eb+wGl3QKjlZfU80H++p5f28DH+9vpKvHT3SEk8uLsrjmzFwW5CfjkLZ4IcZVeDa/gHEi0pYVsPdtmPEZs6uxnIFNNXcsmYqvN8CGg038eVMlr5VVs2pDBXnJ0Vw9P5fPzc9hUnK02SULIbDzkbq/B35+BjhccPvfISb11H1WmOn09fLmthpWbajgg30NaA2LpqTw+TNzuawok+gI+x4rCGG28Bz90qdiAzxzOWTPh5tfBlfEqf28MFTR1MlLGytZtbGCgw2dxASbZ66cm80ZkxKJ98h8NEKEUniHOkDZKnjhSzD3Jlj6/8PuLNPxorWm5GATq0oqeHVLFR0+Y/bIgtQYCnMSmBNsypmdEy9BL8QYhG+bep+iz0PdLlj7OKTPgHPuMbsiW1JKsSA/mQX5yXz/yll8vL+RrZUtlFW2sPFgE69srjq67PFBPy8vEY/baWL1QtiH/UMd4IJ/g7qd8NfvQurpcPolZldka9ERLi6Yns4F09OPvtbQ3k1ZZcugQR/pcrBoagoXTk/nwunp5KVIp6sQJ8v+zS99fB3w28ugoRy+9FfImDV+ny0G1dDezZaKFtbuqeOdXXXsr+8AYEpazNGAX1CQRKRLjuKF6BOSNnWl1KXAzwEn8But9Y+Pe38J8DNgDnCd1nrVcOsc91AHaKmE/7nI6DC9fY2MiJlg9td38M4uY46af5Q34OsNEB3h5NzTUrlwejpnT0kmI95DdIRTpjEQYWvMoa6UcgK7gU8DFcB64Hqt9fYBy+QD8cA3gNUTNtRhwIiYecERMXJi0kTU6evlw30NrNlVy5qddVQ2dx19z+N2kBobGbxFHH2cMuDxlLQY0uMiJfyF7YSio3QhsFdrXR5c4XJgKXA01LXWB4LvBcZU7XjIPROWPmmMiHn1ARkRM0FFR7j41MwMPjUzA601e2vb2VzRQn17N/Vt3TR0+Khv76aiqYvNFS00dvjwH3cx7uSYCGZmxTEzM56ZWcbttPRYIlwjm+St1x+gvt1HXVs39R3d5CVHMyU1RnYUYkIbSajnAIcHPK8Azjo15YyTos9D/W549z9kRIwFKKWYlhHHtIy4IZcJBDRNnT4aOnzUtnazp7aNndVt7Khp5ff/OEh3r3G84XYqpqbFBkM+jsyEKBrau6lt66a2tZu69m5qW73UtXXT2Onj+B+yyTERnDk5iQX5SRTnJ1OYnTDinYQQ42FcR78ope4A7gDIy8sbz4/+pPMf7h8RkzINpl9qbj1iTBwORUpsJCmxkZyeEcd50/r7S3r9AQ40dLC9uo0d1a3srG7lw30NvLSp8ugyLociLS6S9LhIcpOimZeXRHpcJOnxkaTFRpIcE8G+unbWH2ii5EAjb20/Ahgjd+ZOSqQ4GPLz85JIiJJx+MI8I2lTXwQ8orW+JPj83wC01j8aZNlngFcndJv6QL7O4IiYvfClt2RETJhpDDbhpMZGkhjlHtXkZLVtXjYcaGL9gSY2HGxka1Ur/oBGKchNiiLC6cDlcOByKlwOhcvpCN4rXA4HbqfC7XQwLSOOswuSmZeXRFSEjPIRwwtFR6kLo6P0U0AlRkfpDVrrbYMs+wxWCnWA1ir49YWg/caFq0/7NOSfC+4osysTFtLR3cvmw82sP9BEeX07vX5NbyBAr1/TE9D4AwF6/Bp/QNPrNx57e/0cqO8goI1moTm5iSwsSOasgmTOnJxEnJx5KwYRqiGNl2MMWXQCT2utf6iUehQo0VqvVkotAF4CkgAvUKO1nn2idU6YUAeoKYO3fwAH3oNeL7g8kH+eEfDTPg0pU82uUNhUq7eHDQeb+Ki8kY/3N7ClooXegMahYHZ2AmcVJLMwGPIpcl1Zgcz9Mjo9XXDgfdj7Fux5Cxr3Ga8nFRjhftqnjbCPkDMexanR6etl06FmPtrfyEflDWw63Iwv2MmbGO2mIDWGgtQYpqTGMCUtloLUGPJTYqTpJoxIqI9FYznsedsI+f3vQW8XOCONk5aUo//mcAYfB+8dwdcTJsFlj0NCjtlbIiyqu9fP5sMtbKloZn99B+V1Heyv76Cm1XvMcjmJUUbAp0YT5XYS0BDQGq3BH9AEtCagjYnX+h7HRrqYk5vAvLwkuS6thUioh0qPFw6ug31rwNsMgQDogNEWrwMQCN4PvB14H9we+MKzMPkcs7dA2EhHdy/76zuOuZXXtXOgoZMefwCHUigFDqVwOhQOZQwNdQRfcyhFc6fv6GyaidFu5k5KZN6kJOblJXLGpMRhR/F0+fxUNndRNeDW0tVDpNtJpMsRvDmJdA947HIQ6XbgcTmZlhFHWpw0KY2WhLqZ6nbB8hug6QBc+mNY8GU50UlMGP6AcVLXpkNNbDrUzKbDTeypbT86Nn9qWgzz8pKYk5uArzdAZXMXlU1dVLV0UdXspbHDd8z6HAriPG58vQG8vf5PjPEfTH5KNGdOTg6O+09ialqs/GIYhoS62bwtweulvmHM6f6Z/zSO3oWYgNq8PWypaGHToSZKDzez6VAzDcHwjo5wkpMYRXZiFDlJUcHHHnISo8lO9JAR78HtNE7E0lrTG9B09wbo7vEb970Bunv9dPcE6OjuZWtVS3BIaNPRHURStJszJycdDfrCnAQ8bidaa5o7e6hp9VLT4qWm1Ut1i5cjwcc1LV7q2rtJiHKTG6wtN6mvzmhyk6LIiPfgtME1dSXUJ4JAAN79sXEGa/Z8uPYP0s4uLEFrTXWLl+gIJwlR7lNyFK21Zn99ByUHmig52EjJwSbK64wZOyOcDtLjI6lr6z56VnAfpSA1NpKsBGOHkhYXSUtnDxXNXVQ2dVLffuwvCZdDkZXoIScxisx4D3EeN3Ee14B7F/HHvRYf5SY2cmLNUC6hPpHseBVe+qq0swsxjIb2bjYcNI7ia1q9ZMQbwd0X4FkJRoj3/TIYTF+bf2VzFxVNnVQ29T3uorbNS5u3lzZv7yfmDDpeamwkM7PimJXVP4fQlLSYE372qSShPtFIO7sQE4bWmq4eP+3eXlq9vbR5e46GfZu3h+auHvbWtrOjupU9R9rx+Y1fCxEuB6dnxB4zWVxmgie4nh5au3qC9wOf9x59/cuLp3DJ7MyTqlkuZzfRpE2H2/9utLO//g2oKpV2diFMopQiOsJFdISL9PgTL9vjD7Cvzgj4HcF5hNbsquVPGypO+HcOBfFR7qPNO/EeN45TeCAnR+pmCQTgnR8Z107Nng9zbwC/DxeEZcYAAAqjSURBVHq7wd8D/u7gY1/wdZ/xmjMCMmZD5hzImgNRSWZviRBhrbbNy47qNhrau43QjnITH+U6+jgmxBd1keaXia6vnd3XduzrymlcwMMZ0X/vjICeTmir7l8uIc8I96wz+oM+LkuadISwKWl+mehmXgFTdxnXUB0Y4I4TnPbdUQ/Vm6FmC1RvMR7vfLX//ehUI9zTZkDyFOOWMtU4w/VE6x2osxFqt8OR7cZ97XZjDvrEPJhyIUy9ECadLc1GQkwwcqRuF91tULO1P+hrNkPDPuPIvo8zApLyg0E/FVKC95FxxtzytTvgyDbjvr2m/+88CZA+G1KnQf0eqPgYAr3gioLJi/pDPqPQ3F8IWkNXEzQfMnY+0cnm1SLEKSLNL+FMa6OpprHcCPjGfcH7cuPWe+z8Ibg8Rkdu+mxIn2nML58+65PNOd1txhQI5WuMaRPqdxmvx6TBlAuMkJ+8yPhl4Azx9LEBP7RUQNN+YwRR4/4Bjw9Ad0twQWX0PUw+15hKefK54XGh8UDA+K5CuXPtaja+x4iY0K1TnDQJdTG4QCAY+PvA2xpsqikYefPMQC2VUP5O/62jNviGgtgMiM82bgm5wcc5xi0hx9hh+H3Q2WDcOhr6H3c2QGd98L7RqLf5kPEroY/DDUmTjV8gSQXGNiTkGk1FB96Hwx/1/1pJm2HMsjn5XOM+Nn1M/4QTSvMhWPcz2PR7Y0d87n0w80pwjqGFtXoLvP9z2PaSMcdRZDzEZQZv2cH7LIjPMu77nod6Ry6OIaEuxpfWRhNO1UYj7Fv7blXG8+M7hE9EOY0mlOhUiE6B2LRjwzsp39g5nGhH1OuD6lI4sA4Ovg+H/gG+duO9lGkw6SxIPS3YHHWasd6RXiAlEICWQ8c2W9VuN3ZCfTuzuKwB91lGGMZngScxNEfTjeXw3hOw+Y+AgtlXGf/2DXshcbJx/d25N458umitYf+7Rpjv+ztExMH8m41/+7YaY8faWt3/ONBz7N9HJcHZX4OFd0BU4ti3T3yChLqYWLyt/UHfUmkEg8tjhHbfLSbVCPPIBGMa41Dy9xodywfXGUfyVRuho+7YZeJzjf6GlL6wn2rsQNqPHBvgdTv7dxBgjERKn2n8Amg/Egy/KiPkj+eKMsI+t7i/TyJuFCej1O2G9/4Tyv4EDheceYtxdJ6QazRR7XrdCOaK9RCVbITswtuHboLy98KO1cbfVJcaO6Wz74Qzbxs6nAMB6GocEPRVsOsN2P0X46j+rK8YAS99GyEloS7EcLwt/f0Ox/Q97DM6Xo8XnWI0cWQE+x7SZxlNO54hzl7p8Rodz61Vxq0vBFsOwcEPjSYmMPoypgYDPu+cwY+uj2yDtctg25+NXxTF/2IcjQ+2Q9Da+GXywS+MkHd5YN5NsOguo7McjAvDlD4HH/zS6JdIOQ3OuRfmXHvyI5uqtxg17lgNEbGw4Euw6B7jaN9s/l5o2GMcXKTPMAYBWIyEuhBj0dloBHzTASOU0meHNpwCAThSZjR17Pu7EcJ+n3ExlsmLYOpFxpG89sPanxhDVyNijaPuRXePvPO3bpcR3FtWGH0SMz9r7IjW/6+xU8kphvPuh+mXn1y/ymBqdxg1b3vR2J7i24wdRnzWyNfR4zX6RDwJo6/L22LsBGvKjFFhNVuNmvzd/csk5kFGEWQWGqO3MgshMT/0vxBDSEJdCCvxdcLBD/pDvm5H/3uRCXD2V+Gsr558k0ZbDXz0FKx/2hgpNO0So9lm8jmnbjhq/V6jqWjLCqOpaP4X4dz7jSaetqpj+16Of9z3KwZlBHt0stGcFJX0yceRccbOt6bMuDUf7K8hOgUyi4xbRpHxq+rINjiy1Qj7xn3GhW3A2GlmzO6/xaSBO8YY/RMRbbzvjg4+jwndTnCEJNSFsLLWKmNEUXcbnHFd6JoLutuMI9mE3NCsbyQa98O6n0Lp8/1XDDueJ+HY0VHxOUaIepuNX01dTUY7/tHHTdDdOmAFymhCyizsD/DMIqN56kQ7LV+nsQOt2dof9Ee2DRgiewIujxHy7ijj848OKe177Pjk4wu+CYVXj+qf7+gWSqgLISaU5sOw8VnjCDc+59jhrpFxo1+fv8cYS+9tMZp2QjWeXmvjF0NXs9EE5Gs3wt/XAT0dxr0v+HpPp9FUhDb+Dh28rOUQj+ffAqd96qTKkmkChBATS+IkuOjboVuf0230c4S6I1YpY2cznr9mQmDi9gYIIYQYNQl1IYSwEQl1IYSwEQl1IYSwEQl1IYSwEQl1IYSwEQl1IYSwEQl1IYSwEdPOKFVK1QEHh11wcKlA/bBLWYvdtslu2wP22ya7bQ/Yb5sG257JWushz7QyLdTHQilVcqLTZK3Ibttkt+0B+22T3bYH7LdNJ7M90vwihBA2IqEuhBA2YtVQ/7XZBZwCdtsmu20P2G+b7LY9YL9tGvX2WLJNXQghxOCseqQuhBBiEBLqQghhI5YLdaXUpUqpXUqpvUqph82uZ6yUUgeUUmVKqVKllCUvBaWUelopVauU2jrgtWSl1FtKqT3B+yQzaxyNIbbnEaVUZfB7KlVKXW5mjaOllJqklFqjlNqulNqmlLov+Lolv6cTbI9lvyellEcp9bFSanNwm34QfL1AKfVRMPNWKKUiTrgeK7WpK6WcwG7g00AFsB64Xmu93dTCxkApdQAo1lpb9oQJpdQSoB14VmtdGHztcaBRa/3j4M43SWv9TTPrHKkhtucRoF1r/RMzaztZSqksIEtrvVEpFQdsAP4ZuBULfk8n2J4vYNHvSSmlgBitdbtSyg2sA+4DHgBe1FovV0o9BWzWWv9qqPVY7Uh9IbBXa12utfYBy4GlJtcU9rTWa4HG415eCvwu+Ph3GP/DWcIQ22NpWutqrfXG4OM2YAeQg0W/pxNsj2VpQ3vwqTt408BFwKrg68N+R1YL9Rzg8IDnFVj8i8T40v6qlNqglLrD7GJCKENrXR18XANkmFlMiNytlNoSbJ6xRDPFYJRS+cA84CNs8D0dtz1g4e9JKeVUSpUCtcBbwD6gWWvdG1xk2MyzWqjb0Xla6/nAZcBdwZ/+tqJ132XULe1XwFRgLlAN/Ke55ZwcpVQs8AJwv9a6deB7VvyeBtkeS39PWmu/1noukIvRMjFjtOuwWqhXApMGPM8NvmZZWuvK4H0t8BLGF2kHR4Ltnn3tn7Um1zMmWusjwf/hAsD/YMHvKdhO+wLwnNb6xeDLlv2eBtseO3xPAFrrZmANsAhIVEq5gm8Nm3lWC/X1wLRgb3AEcB2w2uSaTppSKibYyYNSKga4GNh64r+yjNXALcHHtwAvm1jLmPUFX9BVWOx7CnbC/S+wQ2v9xIC3LPk9DbU9Vv6elFJpSqnE4OMojAEhOzDC/fPBxYb9jiw1+gUgOETpZ4ATeFpr/UOTSzppSqkpGEfnAC7geStuj1Lqj8AFGNOEHgG+D/wZWAnkYUyx/AWttSU6H4fYngswftJr4ADwlQFt0ROeUuo84D2gDAgEX/4WRju05b6nE2zP9Vj0e1JKzcHoCHViHHCv1Fo/GsyJ5UAysAm4SWvdPeR6rBbqQgghhma15hchhBAnIKEuhBA2IqEuhBA2IqEuhBA2IqEuhBA2IqEuhBA2IqEuhBA28n8i+a3aZYMWTgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = X_test[200]\n",
        "\n",
        "show_image(new_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "UZOvHg6cOuLq",
        "outputId": "cd915d89-d963-4000-8b2d-e41ce84b4a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_Da0204TiwW",
        "outputId": "fe2f5573-e7f0-432d-a795-a57ca6658913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(new_data.reshape(1, 28, 28))\n",
        "res.argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1m3VJjGTQrq",
        "outputId": "0babf7f7-5bfb-4521-93cc-544346cd37bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.argmax(axis=1)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_coTusITXkr",
        "outputId": "acfd4e9d-68fc-4977-9722-a06da7f6a438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.97      0.98      1032\n",
            "           3       0.97      0.99      0.98      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.99      0.97      0.98       892\n",
            "           6       0.98      0.99      0.99       958\n",
            "           7       0.99      0.98      0.98      1028\n",
            "           8       0.96      0.99      0.97       974\n",
            "           9       0.99      0.96      0.98      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BdavK53OUVCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}